## Peer Review Should Serve Science

<!-- ##### Scientific peer review is systemically toxic, and will be, so long as scientists allow it to be co-opted for social stratification. -->

<!-- em — , en – -->

<!-- **Reviewing research to rank its perceived *importance* is incompatible with reviewing for *accuracy* and *objectivity*.** -->

It is a convenient myth that the primary purpose of peer review is to protect scientific integrity—to ensure research informs without misleading. Indeed, it should be paramount. Outside review is essential to helping ensure research is presented clearly, completely, objectively, and accurately.

However, the overriding purpose of peer review, as it is actually practiced in most of science, is *ranking*. Scientific integrity is a distant second because peer review is the linchpin of the system that we scientists use to rank the value of research and, by extension, to rank each other. We submit our research to conferences and journals each with its own brand and tier of prestige. Each conference and journals has its own peer review processes, reviewers, and standards for acceptance, all of which are chosen to signal its tier of prestige.

These conferences and journals are part of science's larger social stratification system: We rank the importance of research by where it is published; We rank the importance of scientists by their ability to accumulate publications with prestigious brands; We use these rankings to decide who is worthy of acclaim, jobs, trust, and attention.

This stratification system requires peer review committees to reject papers that merely scientific-integrity requirements, lest the top strata would be insufficiently exclusive. They do so by adding requirements such that a research submission be *novel*, *interesting*, *impactful*, or that it meets the particularly nebulous catch-all (or *drop-all* for rejecting any submission) of having a *significant contribution*.

<!-- Ranking conflicts with integrity -->

Not only does ranking render scientific integrity secondary, *ranking requirements* conflict with, and subvert, scientific integrity.

*Ranking requirements bias what gets published.* Submissions that confirm the hopes and beliefs of peer reviewers will be more likely deemed significant, and be accepted, than results that defy reviewers' expectations or dash their hopes. Consider, for example, the consequences when peer review committees deem null results insufficiently interesting or insufficiently impactful. If twenty research teams test an attractive-but-false hypothesis that an intervention will have an effect, we can expect 19 teams to to find no significant difference $p>0.05$ and be fail to publish their work. The only paper to survive peer review and to report the incorrect result that the attractive-but-false hypothesis is true (with the null hypothesis rejected with probability $p<0.05$.)

*Ranking requirements bias how researchers write their papers.* To make papers more more publishable, authors may feel compelled to make them less scientific. Researchers may not document their experimental designs in sufficient detail for results to be replicated, as such mundane information may be deemed tedious and uninteresting by reviewers. Authors are compelled to instead use that space to explain why the results are important. Also, authors are compelled to highlight, and dedicate more space to, experiments or tests that yielded a statistically significant or novel result than tests that did not do so.

*Ranking requirements can be toxic to the ideals of scientists performing research* and trying to publish it. Instead of focusing on scientific integrity, we are forced to focus on meeting subjective expectations of what the peers in our community expect a paper to look like. Those of us who would prefer to leave the interpretation of results and speculation to others are compelled to add subjective "discussion" sections, despite regretting that these cannot help but be tainted by our perspectives, because reviewers expect them. When writing on a new topic that may only have five or ten prior papers relevant enough to cite, we are compelled to add dozens more meet the ever-escalating average citation counts that reviewers expect. We regretfully do this despite believing readers would be better served if we used that space to provide more insight into the smaller set of truly relevant prior work. We lament that papers have evolved to contain ever longer chains of citation numbers, most of which are present only to reduce our chance of rejection, but feel powerless to stop the trend.

We invest time and effort we could be spending furthering science crafting our papers to meet ranking requirements, then are forced to delay publication and revise our papers to meet the subjective expectations of the next set of reviewers based on the subjective feedback of the previous reviewers.

In rejecting papers, reviewers feel obligated to provide feedback that justifies their decision to reject to their fellow committee members, to themselves, and to the authors—feedback that will inevitably focus on shortcomings. A system that must reject the majority of papers, and provide feedback focused on justifying rejection, is toxic to the mental health of the community receiving far more negative feedback than positive feedback. 

*Ranking requirements also toxic to reviewers.* We are burdened by the work of reviewing papers that had already met scientific integrity requirements when previously rejected. Since the game we play encourages authors to re-submit work to new reviewers, any efforts to provide constructive feedback that we might find value in a second reading is likely to be wasted. We feel obligated to participate in peer review because of its importance for protecting scientific integrity, but it is nearly impossible to do so without becoming complicit in the toxicity of the social stratification system built upon it. We are obligated to work with toxic reviewers who abuse the subjectivity of peer review, and to protect their identities, while observing damage they inflict that causes aspiring scientists to abandon careers in science.

<!-- The lies we tell ourselves -->

One lie that allows us to perpetuate the stratification system is that responsibility for peer review's toxicity lies exclusively with the most egregious reviewers. The truth is that they are merely the most visible symptoms of the very cancer we ourselves are feeding.

Another illusion is that as reviewers, we provide value in helping to "curate" research to separate the *important* from the merely *accurate*. In fact, review committees are biased by design to be older and more senior than the average researcher, and so our opinions of what's important are likely to be biased and outdated.

Using peer review for curation may have had value before papers could be shared for free online and before the invention of myriad tools to filter the resulting onslaught of information. While peer review no longer needs to serve this purpose, those of us in Computer Science, whose technical contributions frequently disrupt other industries, are ironically averse to changing with the times.

Lastly, we may believe that there is simply no escape from using peer review for stratification, as the universities and research labs that employ most of us rely on rankings for hiring and promotions.

<!-- But we can -->

But, we *can* and *should* isolate peer review for scientific integrity from that used for ranking. We can start by creating peer review processes strictly scoped to evaluate scientific integrity. Such committees wouldn't evaluate whether a paper is worth publishing, but whether it is as complete, understandable, accurate,and objective as outside reviewers are capable of ensuring. If it is not yet ready to inform readers without misleading, reviewers should explain why and explain what changes are required.

The systems and organizations that currently rely on peer review for ranking can and will adapt.

Review processes that evaluate research that has already cleared a threshold of scientific integrity can focus more clearly 

Conferences justify exclusivity by the limited speaker slots that results from space limits. Peer reviewers select only those papers that attendees will want to see presented or, more paternalistically, those that reviewers they think attendees *should* want to see presented. Attendees then search the list of presentations to see which they want to see and which to skip in favor of the "hallway track". Instead, we could ask those planning to attend the conference to rank what they want to see and optimize the schedule based on their stated preferences. The largest lecture halls could host the presentations with the most interest, presentations with a small but devoted audience could appear in more intimate spaces, and presentations with insufficient interest could be offered online or recorded. Some research, such as replication studies, might not even need to be presented as the authors could simply make themselves available for readers' questions.


could still exist, but with a review process isolated from scientific peer review.
purposes than scientific integrity from ranking without , the stratification system could find there would be are plenty of opportunities outside of peer review to support stratification systems for those that need them.




<!-- View science as a system. Guarded by toxicity. Only those who are immune the the toxicity enter. They become the new guards.
"This is how we've always done it".
Peer review for ranking is endemic to science, it is also toxic to science.
 - Once can't participate in peer review without being complicit in ranking
 - Biases science.
 - We have biased science to include only those comfortable with their complicity in this system. -->



<!-- 
It ensures we have no idea how many experiments were run and discarded because results were insignificant, and so we cannot gauge whether our thresholds of statistical significance are meaningful.   
When scientists need to present that work as *important*, not merely correct, they will inevitably be tempted to subconciously or conciously mislead others.  exclude presenting results that appear unimportant (those with statistically insignificant results), find ways to make results appear more important, or just keep re-submitting their work to different venues until reaching sympathetic reviewers who agree that it is important. Those unwilling to take such measures and tough out the mental health consequences of frequent rejection will be filtered out of scientific careers. -->



<!-- Most every scientist who has submitted work for peer review has received ill-informed, aggressive, or otherwise toxic reviews.

The most comforting explanation for the toxicity that pervades peer review is that the responsible reviewers are a small but egregiously toxic subset that poison the process—the so-called *Reviewer B*s. Alas, it cannot explain how it is possible that most papers submitted for review are rejected despite being co-authored by career scientists who have successfully conducted and published research before.  -->

<!-- Most explanations for the toxicity endemic to scientific peer review conveniently put the blame on to *others*—the *Reviewer B*s that seem to pervasive in our reviews but who cannot be our friends or ourselves. -->

#### Social ranking is harmful to peer review


By perpetuating the co-option of peer review for social ranking, we are responsible for making science less objective and accurate. We create incentives for scientists to report only those tests that surpass a threshold of statistical significance, and not to not report those that fail to reach statistical significance, thereby exaggerating the implied likelihood of those that are reported. We discourage scientists from disclosing reasons why we might not want to trust their results, and we reward those who exaggerate results or contributions.

When peer review committees expect submitted papers to be of a quality that feels subjectively as good as those previously published, they end up rejecting diverse work for simply being different. Thus, scientists expend a great amount of time and effort to meet expectations that have nothing to do with science. For example, most papers in my field typically reference 50-100 citations. Those writing a paper on an emerging topic may only need to cite five or ten citations, but will often add dozens of tangentially-related works to ensure their citation count is at least above the average of past accepted papers and that no reviewer will feel slighted by not having their work cited. The result is that the number of citations grows each year, most research papers have far more citations than they actually need, and so authors no longer have space to actually provide background and insight into the prior work that is actually important for the reader to understand.

The subjectivity of social ranking gives aspiring scientists toxic mixed messages.  We reject intuitive results from being unsurprising or insufficiently novel, then reject results we find too surprising because such counterintuitive findings should not be published without further evidence. We fetishize novelty, encouraging new researchers to chase ideas that others identified as flawed before pursuing. When a novel approach succeeds, we may reject it because we can imagine a less-novel approach that we intuit to be superior that, to meet our subjective definition of a *significant contribution*, should have been tried as well.

Any reviewer self-confident enough to believe that they could have done a better job of designing, conducting, or presenting another's research can reject it for choices they didn't approve of.

When forced to justify why papers failed to meet our subjective criteria, we are more likely to focus on criticizing the work than on encouraging the changes that would make it reach our standards of objectivity and accuracy. To justify rejection on subjective criteria, the feedback is often itself nebulous (e.g., "the authors should do more to clarify their contribution.") Toxicity is inevitable when the primary purpose of feedback is to justify a decision and our social stratification system demands that most decisions are rejection.


Some advocates for co-opting peer review for subjective purposes believe that senior scientists should *curate* research so that others know what to consume. Aside from the questionable premise that senior scientists can see the future better than junior scientists, making peer review the mechanism for gatekeeping does not help junior scientists avoid investing time into ideas their elders are skeptical of---it only hinders their ability to share the outcome of that investment.

Adding myriad arbitrary justifications for rejecting scientific works from publication, and thereby delaying the dissemination of their findings, impedes scientific progress. It also forces us all to spend more time reviewing previously-rejected papers, and revising our own papers to meet the subjective whims of a previous reviewers (often only to have future reviewers objective to those changes.)

Lastly, but perhaps most importantly, a system that requires publications to be exclusive ensures that most of the feedback scientists will receive is that their work is not good enough. This is harmful to their mental health, and ensures that only those without sufficiently "thick skins" will survive as scientists.

#### Isolating scientific peer review from social ranking

Is the design sound. (Before conducting.)

Was it competently conducted and are the results presented accurately (after).  May not necessarily include conclusions beyond what is immediately clear from the paper.

Are the results worthy of attention? Where does it deserve to be presented? Does it deserve recognition?

We must create different systems for scientific peer review and for social ranking.

In a world with finite money, attention, and other resources, scientists will always need to compete in what may seem like zero-sum games.
When there is a conflict of interest, isolate it (don't ignore it).

Why must we make a decision on what is worthy of publication after an experiment is conducted, as to opposed to when it is designed?

In a world where information is effectively instant and free, and presentations can be in person or remote, why should program committees decide which research deserves a 1000-seat auditorium and which deserves to be available only online?



### How to separate

Curation will always be subjective, but learning that others are less interested in the questions you are investigating is less harmful than being rejected from a process with the implication that you have failed in other ways.

"Curation" is easy to add later. Journals that invite reviewed papers.  Conferences that distribute presentation space based on interest.

Liberates us to put review before running studies.

<!-- It will be impossible to participate in reviewing scientific work without being complicit in the mental health harms to scientists, and would-be scientists, of social stratification. -->


<!-- Sadly, this makes it impossible to participate in a process supposedly key to scientific objectivity without becoming complicit in the mental health harms to scientists and would-be scientists .  -->

<!-- The zero-sum game of distributing prestige is toxic to scientific objectivity and to the mental health of scientists and would-be scientists. When integrated into  and is a cancer on science itself.  Cue the offspring. -->

<!-- ### Why status ranking is inherently toxic

To make a publication selective, conferences and journals must determine whether research papers constitute a "significant contribution" worthy of the status of being associated with their brand.

The ambiguity in what "contribution" even means opens the floodgates of subjectivity, giving reviewers a blank check to reject work because they weren't sufficiently convinced it was important, or because it didn't cite work that they thought was worth mentioning, or because the way was organized in a way that they wouldn't have organized it. Anyone self-confident enough to believe that they could have done a better job of designing, conducting, or presenting the research can reject you for not doing what they would have done. -->

<!-- Destroy trust in the review process -->

When authors submit to a review process that uses subjective metrics, rather than scientific objectivity, they will optimize for those metrics. This reduced integrity, as some authors will try to inflate their importance of their findings or outright cheat. It also wastes a lot of time, as authors will take a paper that only builds on five or ten other prior papers worth citing, but will then add 50 or 100 citations so as not to have a below-average citation count and to ensure they don't risk citing work by potential reviewers who might fault the paper for not being deferential to their past contributions. Writing papers defensively in anticipation of subjective reviewing can be exhausting, especially when one failure to appease a reviewer's ego can set your publication date back by months or years.

But the real cost is to mental health.





<!-- As a member of a peer review committee, can dismiss a paper by arguing that authors should do a better job justifying the importance of the question they are investigating, or because the authors weren't sufficiently deferential to prior research, or because they didn't structure to put sections an order that reviewers prefer. -->

### Curation


#### Biasing participation to exclude

As a new graduate student, learning to recognize the abusiveness of this practice is key to surviving it and, hopefully, refusing to join those who accept as necessary (or at least inevitable).

You don't have the least power, and the system is designed to protect those with power over you.
Those who have power 
Your paper may be rejected because reviewers who compete with your advisor don't like the topic your advisors suggested you work on, or because you failed to cite their work, or because they didn't like.  . 

# Why is peer review abusive

Evaluate science to ensure that results don't mislead. (Both )

Determine whether research is novel, interesting, or otherwise significant enough to warrant publication at the venue it is being evaluated for.

<!-- Ranking the subjective value of creative work, and those who create it, is incompatible with the scientific process. -->

# It's not okay

Everyone thinks that the review process is random and that feedback is often unconstructive, and often abusive.  Everyone seems to have stories of reviewers who didn't read papers, who intentionally kept competing work out, or who rejected work because the reviewers' favorite work (often their own) wasn't cited.
Reviewer 2 memes.

Yet, nobody thinks they or their are that reviewer, even though many of us frequently confess to delaying reviews until the last minute when we have no choice but to rush them.  The number of peers we think of as abusive or careless and the number of abusive and careless reviews are inconsistent.

Our continued faith in the ritual of peer ritual, despite all the evidence we see as we and our students suffer its abuses, can feel cultish to the new initiate to our tribe.  The best time to prepare for this reality is now, before you establish your loyalty to the tribe, so that you can recognize how abusive it is and resolve not to carry that abuse forward.

# Biases participation in science

You have to be "thick skinned" enough to survive as a scientist despite this abusive process.
You have to be okay with participating in, and thus being complicit in the process.
Values protecting the anonymity of people with more power than you (reviewers) over your mental health.  (Anonymity is designed to protect junior faculty, but students can only aspire to have the power of those who get to subjectively evaluate the importance of their work anonymously and without consequences for errors.)


# 

# Compromises scientific integrity

# Delays the release of information


# Alternatives

Split these two purposes.

Even better, evaluate experiments before they are conducted!


<!--

What you can do:

Learning to recognize toxic behavior and rituals helps you to prevent yourself from being blinded by it, and becoming complicit in it.  Acknowledging the problem is a huge step!


-->
