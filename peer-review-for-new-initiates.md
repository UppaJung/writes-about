## The Systemic Toxin that Poisons Peer Review

<!-- ##### Scientific peer review is systemically toxic, and will be, so long as scientists allow it to be co-opted for social stratification. -->

<!-- em — , en – -->

<!-- **Reviewing research to rank its perceived *importance* is incompatible with reviewing for *accuracy* and *objectivity*.** -->

It is a convenient myth that the primary purpose of peer review is to protect scientific integrity by scrutinizing the accuracy and objectivity of scientific research. Ensuring research does not mislead is, indeed, a noble purpose worth pursuing. No matter how expert scientists are in designing, conducting, and presenting their research, they should invite scrutiny by those who are knowledgeable but disinterested. Those disinterested "peers" may catch errors or misleading statements that authors may have missed, and are less subject to the group think that can evolve among collaborating authors.

However, the overriding purpose of peer review, as it is actually practiced in most of science, is actually that of *ranking*. Peer review is the linchpin of the system that we scientists use to rank the value of research and, by extension, to rank each other. We submit our research to conferences and journals each with has its own brand, tier of prestige, peer review process, and standards for acceptance. Conferences and journals part of a larger social stratification system that ranks the importance of research by where it is published, that ranks the importance of scientists by their ability to accumulate publications with prestigious brands, and that distributes jobs and prestige using these rankings.

This system requires peer review committees to evaluate requirements beyond scientific integrity, for if these were the only standards all publications would have the same standard and too many papers would receive top ranking. So, peer review committees add requirements such that research be *novel*, *interesting*, *impactful*, or that it meets the the particularly nebulous catch-all (or *drop-all* for rejecting any paper) of having a *significant contribution* worthy of the publication.

There are myriad ways in which these *ranking requirements* conflict with, and subvert, scientific-integrity requirements.

Ranking requirements bias what gets published. For example, submissions that confirm the hopes and beliefs of peer reviewers will be more likely deemed significant, and be accepted, than results that defy reviewers' hopes. If peer review committees deem null results uninteresting, and twenty research teams test an attractive-but-false hypothesis, we can expect 19 results to be unpublishable and the only paper to survive peer review and to report the incorrect result that this false hypothesis is true (with the null hypothesis rejected with probability $p<0.05$.)

Ranking requirements can bias how researchers write their papers, making them look more publishable at the risk of making them less scientific. Researchers may not detail their experimental designs in sufficient detail for results to be replicated, as such mundane information may be deemed uninteresting by reviewers. Better to have more space to explain why the results are significant. Also, its better to use space to discuss results that were statistically significant than for those that were not.

Having to write papers to meet ranking requirements can be toxic to those who actually believe in scientific ideals. When writing on a new topic that may only have five or ten prior papers relevant enough to cite, we are compelled to add dozens more meet the ever-escalating average citation counts that reviewers expect. Those of us who would prefer to leave the interpretation of results and speculation to others are compelled to add "discussion" sections tainted by our perspectives. We invest time and effort we could be spending furthering science crafting our papers to meet ranking requirements, then are forced to delay publication and revise our papers to meet the subjective expectations of the next set of reviewers based on the subjective feedback of the previous reviewers. And, of course, there is the mental health impact of a system that demands a high rejection rate.

Ranking requirements also harm reviewers. Our workload will include papers that had already met scientific requirements when previously peer reviewed and rejected. We may provide constructive feedback to authors who will simply re-submit their work to new reviewers without revising it. We feel obligated to participate in peer review because of its importance for protecting scientific integrity, but it is nearly impossible to do so without becoming complicit in the toxicity of the social stratification system built upon it.

And so, many of us have evolved a series of lies that help us ignore our complicity as we perpetuate this system. Many attribute peer review's toxicity to the most egregious reviewers—the most visible symptoms of the very cancer we ourselves are feeding. Others ascribe value in "curating" research to separate the *important* from that which is merely *accurate*, as we did before papers could be shared for free online, before the invention of myriad tools to filter the resulting onslaught of information, and before the introduction of remote presentations that scale to accommodate any number of people who want to attend. We impose constraints that assume that the traditions of scientific communication cannot be change, and that we must continue doing things as we have always done them. Ironically, those of us in Computer Science, whose technical contributions have disrupts other industries are perversely unwilling to see our scientific traditions disrupted.

<!-- To Escaping this system that co-opts peer review for ranking requires that we come to terms with our past complicity and commit to alternatives. -->

<!-- s
 - authors expend time writing and revising papers, and space in papers, to increasing perceived importance
 - work is rejected and publication delayed due to lack of perceived importance.
 - reviewing workloads increase as each peer review process necessitates a new set of reviewers to determine if the work meets that publications' threshold of importance
  -->

<!-- View science as a system. Guarded by toxicity. Only those who are immune the the toxicity enter. They become the new guards.
"This is how we've always done it".
Peer review for ranking is endemic to science, it is also toxic to science.
 - Once can't participate in peer review without being complicit in ranking
 - Biases science.
 - We have biased science to include only those comfortable with their complicity in this system. -->



<!-- 
It ensures we have no idea how many experiments were run and discarded because results were insignificant, and so we cannot gauge whether our thresholds of statistical significance are meaningful.   
When scientists need to present that work as *important*, not merely correct, they will inevitably be tempted to subconciously or conciously mislead others.  exclude presenting results that appear unimportant (those with statistically insignificant results), find ways to make results appear more important, or just keep re-submitting their work to different venues until reaching sympathetic reviewers who agree that it is important. Those unwilling to take such measures and tough out the mental health consequences of frequent rejection will be filtered out of scientific careers. -->



<!-- Most every scientist who has submitted work for peer review has received ill-informed, aggressive, or otherwise toxic reviews.

The most comforting explanation for the toxicity that pervades peer review is that the responsible reviewers are a small but egregiously toxic subset that poison the process—the so-called *Reviewer B*s. Alas, it cannot explain how it is possible that most papers submitted for review are rejected despite being co-authored by career scientists who have successfully conducted and published research before.  -->

<!-- Most explanations for the toxicity endemic to scientific peer review conveniently put the blame on to *others*—the *Reviewer B*s that seem to pervasive in our reviews but who cannot be our friends or ourselves. -->

#### Social ranking is harmful to peer review


By perpetuating the co-option of peer review for social ranking, we are responsible for making science less objective and accurate. We create incentives for scientists to report only those tests that surpass a threshold of statistical significance, and not to not report those that fail to reach statistical significance, thereby exaggerating the implied likelihood of those that are reported. We discourage scientists from disclosing reasons why we might not want to trust their results, and we reward those who exaggerate results or contributions.

When peer review committees expect submitted papers to be of a quality that feels subjectively as good as those previously published, they end up rejecting diverse work for simply being different. Thus, scientists expend a great amount of time and effort to meet expectations that have nothing to do with science. For example, most papers in my field typically reference 50-100 citations. Those writing a paper on an emerging topic may only need to cite five or ten citations, but will often add dozens of tangentially-related works to ensure their citation count is at least above the average of past accepted papers and that no reviewer will feel slighted by not having their work cited. The result is that the number of citations grows each year, most research papers have far more citations than they actually need, and so authors no longer have space to actually provide background and insight into the prior work that is actually important for the reader to understand.

The subjectivity of social ranking gives aspiring scientists toxic mixed messages.  We reject intuitive results from being unsurprising or insufficiently novel, then reject results we find too surprising because such counterintuitive findings should not be published without further evidence. We fetishize novelty, encouraging new researchers to chase ideas that others identified as flawed before pursuing. When a novel approach succeeds, we may reject it because we can imagine a less-novel approach that we intuit to be superior that, to meet our subjective definition of a *significant contribution*, should have been tried as well.

Any reviewer self-confident enough to believe that they could have done a better job of designing, conducting, or presenting another's research can reject it for choices they didn't approve of.

When forced to justify why papers failed to meet our subjective criteria, we are more likely to focus on criticizing the work than on encouraging the changes that would make it reach our standards of objectivity and accuracy. To justify rejection on subjective criteria, the feedback is often itself nebulous (e.g., "the authors should do more to clarify their contribution.") Toxicity is inevitable when the primary purpose of feedback is to justify a decision and our social stratification system demands that most decisions are rejection.


Some advocates for co-opting peer review for subjective purposes believe that senior scientists should *curate* research so that others know what to consume. Aside from the questionable premise that senior scientists can see the future better than junior scientists, making peer review the mechanism for gatekeeping does not help junior scientists avoid investing time into ideas their elders are skeptical of---it only hinders their ability to share the outcome of that investment.

Adding myriad arbitrary justifications for rejecting scientific works from publication, and thereby delaying the dissemination of their findings, impedes scientific progress. It also forces us all to spend more time reviewing previously-rejected papers, and revising our own papers to meet the subjective whims of a previous reviewers (often only to have future reviewers objective to those changes.)

Lastly, but perhaps most importantly, a system that requires publications to be exclusive ensures that most of the feedback scientists will receive is that their work is not good enough. This is harmful to their mental health, and ensures that only those without sufficiently "thick skins" will survive as scientists.

#### Isolating scientific peer review from social ranking

Is the design sound. (Before conducting.)

Was it competently conducted and are the results presented accurately (after).  May not necessarily include conclusions beyond what is immediately clear from the paper.

Are the results worthy of attention? Where does it deserve to be presented? Does it deserve recognition?

We must create different systems for scientific peer review and for social ranking.

In a world with finite money, attention, and other resources, scientists will always need to compete in what may seem like zero-sum games.
When there is a conflict of interest, isolate it (don't ignore it).

Why must we make a decision on what is worthy of publication after an experiment is conducted, as to opposed to when it is designed?

In a world where information is effectively instant and free, and presentations can be in person or remote, why should program committees decide which research deserves a 1000-seat auditorium and which deserves to be available only online?



### How to separate

Curation will always be subjective, but learning that others are less interested in the questions you are investigating is less harmful than being rejected from a process with the implication that you have failed in other ways.

"Curation" is easy to add later. Journals that invite reviewed papers.  Conferences that distribute presentation space based on interest.

Liberates us to put review before running studies.

<!-- It will be impossible to participate in reviewing scientific work without being complicit in the mental health harms to scientists, and would-be scientists, of social stratification. -->


<!-- Sadly, this makes it impossible to participate in a process supposedly key to scientific objectivity without becoming complicit in the mental health harms to scientists and would-be scientists .  -->

<!-- The zero-sum game of distributing prestige is toxic to scientific objectivity and to the mental health of scientists and would-be scientists. When integrated into  and is a cancer on science itself.  Cue the offspring. -->

<!-- ### Why status ranking is inherently toxic

To make a publication selective, conferences and journals must determine whether research papers constitute a "significant contribution" worthy of the status of being associated with their brand.

The ambiguity in what "contribution" even means opens the floodgates of subjectivity, giving reviewers a blank check to reject work because they weren't sufficiently convinced it was important, or because it didn't cite work that they thought was worth mentioning, or because the way was organized in a way that they wouldn't have organized it. Anyone self-confident enough to believe that they could have done a better job of designing, conducting, or presenting the research can reject you for not doing what they would have done. -->

<!-- Destroy trust in the review process -->

When authors submit to a review process that uses subjective metrics, rather than scientific objectivity, they will optimize for those metrics. This reduced integrity, as some authors will try to inflate their importance of their findings or outright cheat. It also wastes a lot of time, as authors will take a paper that only builds on five or ten other prior papers worth citing, but will then add 50 or 100 citations so as not to have a below-average citation count and to ensure they don't risk citing work by potential reviewers who might fault the paper for not being deferential to their past contributions. Writing papers defensively in anticipation of subjective reviewing can be exhausting, especially when one failure to appease a reviewer's ego can set your publication date back by months or years.

But the real cost is to mental health.





<!-- As a member of a peer review committee, can dismiss a paper by arguing that authors should do a better job justifying the importance of the question they are investigating, or because the authors weren't sufficiently deferential to prior research, or because they didn't structure to put sections an order that reviewers prefer. -->

### Curation


#### Biasing participation to exclude

As a new graduate student, learning to recognize the abusiveness of this practice is key to surviving it and, hopefully, refusing to join those who accept as necessary (or at least inevitable).

You don't have the least power, and the system is designed to protect those with power over you.
Those who have power 
Your paper may be rejected because reviewers who compete with your advisor don't like the topic your advisors suggested you work on, or because you failed to cite their work, or because they didn't like.  . 

# Why is peer review abusive

Evaluate science to ensure that results don't mislead. (Both )

Determine whether research is novel, interesting, or otherwise significant enough to warrant publication at the venue it is being evaluated for.

<!-- Ranking the subjective value of creative work, and those who create it, is incompatible with the scientific process. -->

# It's not okay

Everyone thinks that the review process is random and that feedback is often unconstructive, and often abusive.  Everyone seems to have stories of reviewers who didn't read papers, who intentionally kept competing work out, or who rejected work because the reviewers' favorite work (often their own) wasn't cited.
Reviewer 2 memes.

Yet, nobody thinks they or their are that reviewer, even though many of us frequently confess to delaying reviews until the last minute when we have no choice but to rush them.  The number of peers we think of as abusive or careless and the number of abusive and careless reviews are inconsistent.

Our continued faith in the ritual of peer ritual, despite all the evidence we see as we and our students suffer its abuses, can feel cultish to the new initiate to our tribe.  The best time to prepare for this reality is now, before you establish your loyalty to the tribe, so that you can recognize how abusive it is and resolve not to carry that abuse forward.

# Biases participation in science

You have to be "thick skinned" enough to survive as a scientist despite this abusive process.
You have to be okay with participating in, and thus being complicit in the process.
Values protecting the anonymity of people with more power than you (reviewers) over your mental health.  (Anonymity is designed to protect junior faculty, but students can only aspire to have the power of those who get to subjectively evaluate the importance of their work anonymously and without consequences for errors.)


# 

# Compromises scientific integrity

# Delays the release of information


# Alternatives

Split these two purposes.

Even better, evaluate experiments before they are conducted!


<!--

What you can do:

Learning to recognize toxic behavior and rituals helps you to prevent yourself from being blinded by it, and becoming complicit in it.  Acknowledging the problem is a huge step!


-->
