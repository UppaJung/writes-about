# _We_ are Why Peer Review is Toxic:<br> A guide for aspiring scientists

##### Scientific peer review is systemically toxic, and will be, so long as we allow it to be co-opted for social stratification.

When we introduce the concept of peer review to aspiring scientists, the press, and other outsiders, we typically focus on the noble goal of protecting objectivity and accuracy of research. We explain how, no matter how expert we are in designing, conducting, and presenting research, we can improve it by inviting disinterested parties to scrutinize our work. After all, those who are not invested in the research are less likely to overlook mistakes that we may subconsciously ignore in our own work, and are not subject to the group think that can evolve among collaborators.

Tellingly, we tend not to reveal to those unfamiliar with how peer review actually works that, in much of science, it has been co-opted to rank research and, by extension, to rank the scientists performing that research. Most peer review is conducted by conferences and journals, each with has its own brand, tier of prestige, and expectations for what makes research worthy of publication. These expectations go beyond the scientific imperatives of objectivity and accuracy, introducing subjective goals such as *novelty,* *impact,* and the particularly nebulous catch-all (or *drop-all* for rejecting any paper) of *significance of contribution*. These conferences and journals exist within a larger social stratification system that ranks research by where it is published, ranks scientists by their ability to accumulate publications with prestigious brands, and distributes jobs and notoriety using these rankings.

Ranking research by whether it is worthy of attention and acclaim subverts the scientific goals of accuracy the objectivity. Yet, most everyone who participates in peer review accept its co-option unquestioningly. How are scientists so easily co-opted in subverting science?

Peer review committees are made up almost entirely of those who thrived as scientists, or at least survived, despite the toxic impact of this co-option. Further, maintaining status in the social stratification system requires one to participate in it when authoring or reviewing research, further perpetuating it. To avoid reckoning with our complicity in this system, most of us learn to attribute its toxicity to its most egregious reviewers -- the most visible symptoms of the very cancer we ourselves are feeding.

Perpetuating the co-option of scientific peer review for social stratification is, in fact, a choice, and one we should not make without reckoning with the consequences and alternatives. 


#### The consequences of co-option
By perpetuating the co-option of peer review for social ranking, we are responsible for making science less objective and accurate. We create incentives for scientists to report only those tests that surpass a threshold of statistical significance, and not reporting those that don't, thereby exaggerating the implied likelihood that hypotheses deemed significant are in fact true. We reward those who exaggerate results. We discourage scientists from disclosing reasons why we might not want to trust their results.

Embracing the subjectivity of social ranking gives aspiring scientists toxic mixed messages. We tell them to pursue novel approaches, then reject them because we would have taken a different approach. We reject intuitive results from being unsurprising or insufficiently novel, and reject other results because they are counterintuitive and should not be published without further exploration to explain them. Because our feedback must justify our social ranking decision we explain why the work failed to receive more praise ("needs more clarity on contribution") and often gloss over the specifics necessary to ensure it can be published without misleading readers.

When peer review committees expect submitted papers to be of a quality that feels subjectively as good as those previously published, they end up rejecting diverse work for simply being different. Thus, scientists expend a great amount of time and effort to expectations that are unrelated to the goals of science. For example, most papers in my field have a related work section with over 50 citations, often running beyond 100. Those writing a paper on a novel topic that only needs five to ten citations will often add dozens of tangentially-related works to ensure their citation count is at least above the average of past accepted papers. The result is that the number of citations grows each year, most research papers have far more citations than they actually need, and so few papers actually have space to provide background and insight into the prior work that is actually important for the reader to understand. Similarly, while the amount of information in research papers varies greatly, almost all will fit in exactly the limit given by the submission instructions.

Because we reject papers for myriad reasons other than inaccuracy, we delay the dissemination of information and advancement of science.



Some advocates for our system of peer review believe that we play an important role in "curating" research for others to consume.

We are responsible for discouraging our fellow scientists from performing work that makes incremental progress, or confirms prior results, both of which are critical to the advancement of science.




In a world with finite money, attention, and other resources, scientists will always need to compete in what may seem like zero-sum games.
When there is a conflict of interest, isolate it (don't ignore it).

"Curation"

Why must we make a decision on what is worthy of publication after an experiment is conducted, as to opposed to when it is designed?

In a world where information is effectively instant and free, and presentations can be in person or remote, why should program committees decide which research deserves a 1000-seat auditorium and which deserves to be available only online?


<!-- Donâ€™t hate the player, hate the game. -->



<!-- The ritual of peer review has such a sacred role in science that we, like members of religions and cults, blind ourselves its harms and its dissonance with our values. -->

<!-- Like religions and cults, science has a ritual so sacred to us that we blind ourselves to its harms and its dissonance with our values: peer review. -->


<!-- Outside perspectives are also important , our mere our choice to use a particular experimental design is itself bayesian evidence for suspicion--for any flawed research design, only those incapable of seeing the design's flaws will use it unwittingly. -->


<!-- To anyone not blinded through membership in our cult, it seems obvious that a process employed for social stratification cannot help but become toxic.
But, to deprogram my fellow scientists, and to help inoculate aspiring scientists, I will detail the inevitable consequences of this choice that we who perpetuate this system are complicit in.
I will then debunk the common argument that we have no choice but to conduct peer review in this way for lack of better alternatives, so that we can begin to remove this cancer on science itself. -->

<!-- Our perversion of peer review has made it less objective and is a cancer on science itself. It is time to open our eyes to the harms of this avoidable choice and our complicity in perpetuating these systems in the presence of alternatives. -->

### Problems

Discourages null results and replications resulting in survivor bias.
The most unexpected results are the most interesting, but also those we should be most suspicious of.
An idea may appear novel simply because others who have thought of it discarded it for good reason.


#### Increases subjectivity

##### Gatekeeping


#### Disincentivizes integrity

#### Slows science

#### Decreases diversity of contribution types

#### Unnecessary work
Citations, revisions, conforming to expectations


### How to separate

Curation will always be subjective, but learning that others are less interested in the questions you are investigating is less harmful than being rejected from a process with the implication that you have failed in other ways.

"Curation" is easy to add later. Journals that invite reviewed papers.  Conferences that distribute presentation space based on interest.

Liberates us to put review before running studies.

<!-- It will be impossible to participate in reviewing scientific work without being complicit in the mental health harms to scientists, and would-be scientists, of social stratification. -->


<!-- Sadly, this makes it impossible to participate in a process supposedly key to scientific objectivity without becoming complicit in the mental health harms to scientists and would-be scientists .  -->

<!-- The zero-sum game of distributing prestige is toxic to scientific objectivity and to the mental health of scientists and would-be scientists. When integrated into  and is a cancer on science itself.  Cue the offspring. -->

### Why status ranking is inherently toxic

To make a publication selective, conferences and journals must determine whether research papers constitute a "significant contribution" worthy of the status of being associated with their brand.

The ambiguity in what "contribution" even means opens the floodgates of subjectivity, giving reviewers a blank check to reject work because they weren't sufficiently convinced it was important, or because it didn't cite work that they thought was worth mentioning, or because the way was organized in a way that they wouldn't have organized it. Anyone self-confident enough to believe that they could have done a better job of designing, conducting, or presenting the research can reject you for not doing what they would have done.

<!-- Destroy trust in the review process -->

When authors submit to a review process that uses subjective metrics, rather than scientific objectivity, they will optimize for those metrics. This reduced integrity, as some authors will try to inflate their importance of their findings or outright cheat. It also wastes a lot of time, as authors will take a paper that only builds on five or ten other prior papers worth citing, but will then add 50 or 100 citations so as not to have a below-average citation count and to ensure they don't risk citing work by potential reviewers who might fault the paper for not being deferential to their past contributions. Writing papers defensively in anticipation of subjective reviewing can be exhausting, especially when one failure to appease a reviewer's ego can set your publication date back by months or years.

But the real cost is to mental health.





<!-- As a member of a peer review committee, can dismiss a paper by arguing that authors should do a better job justifying the importance of the question they are investigating, or because the authors weren't sufficiently deferential to prior research, or because they didn't structure to put sections an order that reviewers prefer. -->

### Curation





### Consequences

As such, peer review committees have become the battle grounds in which the senior members of research communities argue over what ideas and directions are "important" and worthy of presentation. New initiates to our scientific endeavor are often collateral damage, especially those without powerful allies and those brave enough to pioneer work in areas that others have yet to grasp the importance of.


### Consequences

Biases participation against those who put up with these consequences.

#### Wasted time

New researchers quickly discover that time they thought they would be dedicating to running experiments and learning new things is, in fact, dedicated to rewording their findings so as not to offend or unnerve.
It's bad for reviewers too!

#### Delayed results
#### Mental health

A 20% accept rate means 80% of participants are being told they're not good enough.

#### Biasing participation to exclude

As a new graduate student, learning to recognize the abusiveness of this practice is key to surviving it and, hopefully, refusing to join those who accept as necessary (or at least inevitable).

You don't have the least power, and the system is designed to protect those with power over you.
Those who have power 
Your paper may be rejected because reviewers who compete with your advisor don't like the topic your advisors suggested you work on, or because you failed to cite their work, or because they didn't like.  . 

# Why is peer review abusive

Evaluate science to ensure that results don't mislead. (Both )

Determine whether research is novel, interesting, or otherwise significant enough to warrant publication at the venue it is being evaluated for.

<!-- Ranking the subjective value of creative work, and those who create it, is incompatible with the scientific process. -->

# It's not okay

Everyone thinks that the review process is random and that feedback is often unconstructive, and often abusive.  Everyone seems to have stories of reviewers who didn't read papers, who intentionally kept competing work out, or who rejected work because the reviewers' favorite work (often their own) wasn't cited.
Reviewer 2 memes.

Yet, nobody thinks they or their are that reviewer, even though many of us frequently confess to delaying reviews until the last minute when we have no choice but to rush them.  The number of peers we think of as abusive or careless and the number of abusive and careless reviews are inconsistent.

Our continued faith in the ritual of peer ritual, despite all the evidence we see as we and our students suffer its abuses, can feel cultish to the new initiate to our tribe.  The best time to prepare for this reality is now, before you establish your loyalty to the tribe, so that you can recognize how abusive it is and resolve not to carry that abuse forward.

# Biases participation in science

You have to be "thick skinned" enough to survive as a scientist despite this abusive process.
You have to be okay with participating in, and thus being complicit in the process.
Values protecting the anonymity of people with more power than you (reviewers) over your mental health.  (Anonymity is designed to protect junior faculty, but students can only aspire to have the power of those who get to subjectively evaluate the importance of their work anonymously and without consequences for errors.)


# 

# Compromises scientific integrity

# Delays the release of information


# Alternatives

Split these two purposes.

Even better, evaluate experiments before they are conducted!


<!--

What you can do:

Learning to recognize toxic behavior and rituals helps you to prevent yourself from being blinded by it, and becoming complicit in it.  Acknowledging the problem is a huge step!


-->
