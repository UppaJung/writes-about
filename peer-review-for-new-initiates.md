## The Systemic Toxin that Poisons Peer Review

<!-- ##### Scientific peer review is systemically toxic, and will be, so long as scientists allow it to be co-opted for social stratification. -->

<!-- em — , en – -->

**Ranking the *importance* of scientific research, so as to rank research and the scientists conducting it, is incompatible with protecting scientific *integrity*.**


Most scientists describe peer review to outsiders as a process for protecting scientific *integrity*. We explain that, no matter how expert we are in designing, conducting, and presenting research, we can make our work more accurate and objective by inviting disinterested parties to scrutinize it. After all, those who are not invested in the research are more *objective*: they are less likely to overlooking errors or misleading statements that we may subconsciously ignore in our own work, and are not subject to the group think that can evolve among collaborators.

<!-- Alas, this ideal of scientific peer review, as a mechanism for truth and objectivity is mostly a fiction.

**Peer review has been co-opted as a mechanism of social stratification, and this co-option is a toxin that is antithetical to our scientific goals and ideals.** -->

But *integrity* is too often only the secondary purpose of peer review. New PhD students and other aspiring scientists quickly learn that peer review is the linchpin of the system that we scientists use to rank research and, by extension, to rank each other. We submit our research to conferences and journals each with has its own brand, tier of prestige, and peer review process. Each of these publications' peer review committees have their own expectations for what makes research *important* enough to publish, which go far beyond ensuring that it does not mislead. They introduce subjective measures such as *novelty,* *impact,* and the particularly nebulous catch-all (or *drop-all* for rejecting any paper) of *significance of contribution*.

Conferences and journals exist within a larger social stratification system that ranks the importance of research by where it is published, that ranks the importance of scientists by their ability to accumulate publications with prestigious brands, and distributes jobs and prestige using these rankings of importance. These publications must reject research that may be *merely* non-misleading (or can be easily revised to meet these goals) lest all such research would appear to be of equal importance.

Because almost all the publications available to us and all the peer review committees we can serve on operate this way, it is nearly impossible to participate in science without becoming complicit in a toxic system of social stratification.

And it is toxic. When scientists need to present that work as *important*, not merely correct, they will inevitably be tempted to exclude presenting results that appear unimportant (those with statistically insignificant results), find ways to make results appear more important, or just keep re-submitting their work to different venues until reaching sympathetic reviewers who agree that is is important. Thus unwilling to do preserve their integrity and tough out the mental health consequences will be filtered out of scientific careers.

Those of us who survive often create convenient lies to avoid reckoning with our complicity. We attribute peer review's toxicity to the most egregious reviewers—the most visible symptoms of the very cancer we ourselves are feeding. 

And so, the system perpetuates itself such that, even after the information age gave us the ability to publish papers for free, provided myriad tools to filter the resulting onslaught of information, and gave us the ability to present our work remotely to anyone who wanted to listen, we still conduct peer review paternalistically as if others need reviewers to protect them from work they might find *unimportant*.

Escaping this system that co-opts peer review for social ranking requires that we accept our complicity in perpetuating it and committing ourselves to working towards alternatives.


<!-- Most every scientist who has submitted work for peer review has received ill-informed, aggressive, or otherwise toxic reviews.

The most comforting explanation for the toxicity that pervades peer review is that the responsible reviewers are a small but egregiously toxic subset that poison the process—the so-called *Reviewer B*s. Alas, it cannot explain how it is possible that most papers submitted for review are rejected despite being co-authored by career scientists who have successfully conducted and published research before.  -->

<!-- Most explanations for the toxicity endemic to scientific peer review conveniently put the blame on to *others*—the *Reviewer B*s that seem to pervasive in our reviews but who cannot be our friends or ourselves. -->

#### Social ranking is harmful to peer review


By perpetuating the co-option of peer review for social ranking, we are responsible for making science less objective and accurate. We create incentives for scientists to report only those tests that surpass a threshold of statistical significance, and not to not report those that fail to reach statistical significance, thereby exaggerating the implied likelihood of those that are reported. We discourage scientists from disclosing reasons why we might not want to trust their results, and we reward those who exaggerate results or contributions.

When peer review committees expect submitted papers to be of a quality that feels subjectively as good as those previously published, they end up rejecting diverse work for simply being different. Thus, scientists expend a great amount of time and effort to meet expectations that have nothing to do with science. For example, most papers in my field typically reference 50-100 citations. Those writing a paper on an emerging topic may only need to cite five or ten citations, but will often add dozens of tangentially-related works to ensure their citation count is at least above the average of past accepted papers and that no reviewer will feel slighted by not having their work cited. The result is that the number of citations grows each year, most research papers have far more citations than they actually need, and so authors no longer have space to actually provide background and insight into the prior work that is actually important for the reader to understand.

The subjectivity of social ranking gives aspiring scientists toxic mixed messages.  We reject intuitive results from being unsurprising or insufficiently novel, then reject results we find too surprising because such counterintuitive findings should not be published without further evidence. We fetishize novelty, encouraging new researchers to chase ideas that others identified as flawed before pursuing. When a novel approach succeeds, we may reject it because we can imagine a less-novel approach that we intuit to be superior that, to meet our subjective definition of a *significant contribution*, should have been tried as well.

Any reviewer self-confident enough to believe that they could have done a better job of designing, conducting, or presenting another's research can reject it for choices they didn't approve of.

When forced to justify why papers failed to meet our subjective criteria, we are more likely to focus on criticizing the work than on encouraging the changes that would make it reach our standards of objectivity and accuracy. To justify rejection on subjective criteria, the feedback is often itself nebulous (e.g., "the authors should do more to clarify their contribution.") Toxicity is inevitable when the primary purpose of feedback is to justify a decision and our social stratification system demands that most decisions are rejection.


Some advocates for co-opting peer review for subjective purposes believe that senior scientists should *curate* research so that others know what to consume. Aside from the questionable premise that senior scientists can see the future better than junior scientists, making peer review the mechanism for gatekeeping does not help junior scientists avoid investing time into ideas their elders are skeptical of---it only hinders their ability to share the outcome of that investment.

Adding myriad arbitrary justifications for rejecting scientific works from publication, and thereby delaying the dissemination of their findings, impedes scientific progress. It also forces us all to spend more time reviewing previously-rejected papers, and revising our own papers to meet the subjective whims of a previous reviewers (often only to have future reviewers objective to those changes.)

Lastly, but perhaps most importantly, a system that requires publications to be exclusive ensures that most of the feedback scientists will receive is that their work is not good enough. This is harmful to their mental health, and ensures that only those without sufficiently "thick skins" will survive as scientists.

#### Isolating scientific peer review from social ranking

Is the design sound. (Before conducting.)

Was it competently conducted and are the results presented accurately (after).  May not necessarily include conclusions beyond what is immediately clear from the paper.

Are the results worthy of attention? Where does it deserve to be presented? Does it deserve recognition?

We must create different systems for scientific peer review and for social ranking.

In a world with finite money, attention, and other resources, scientists will always need to compete in what may seem like zero-sum games.
When there is a conflict of interest, isolate it (don't ignore it).

Why must we make a decision on what is worthy of publication after an experiment is conducted, as to opposed to when it is designed?

In a world where information is effectively instant and free, and presentations can be in person or remote, why should program committees decide which research deserves a 1000-seat auditorium and which deserves to be available only online?



### How to separate

Curation will always be subjective, but learning that others are less interested in the questions you are investigating is less harmful than being rejected from a process with the implication that you have failed in other ways.

"Curation" is easy to add later. Journals that invite reviewed papers.  Conferences that distribute presentation space based on interest.

Liberates us to put review before running studies.

<!-- It will be impossible to participate in reviewing scientific work without being complicit in the mental health harms to scientists, and would-be scientists, of social stratification. -->


<!-- Sadly, this makes it impossible to participate in a process supposedly key to scientific objectivity without becoming complicit in the mental health harms to scientists and would-be scientists .  -->

<!-- The zero-sum game of distributing prestige is toxic to scientific objectivity and to the mental health of scientists and would-be scientists. When integrated into  and is a cancer on science itself.  Cue the offspring. -->

<!-- ### Why status ranking is inherently toxic

To make a publication selective, conferences and journals must determine whether research papers constitute a "significant contribution" worthy of the status of being associated with their brand.

The ambiguity in what "contribution" even means opens the floodgates of subjectivity, giving reviewers a blank check to reject work because they weren't sufficiently convinced it was important, or because it didn't cite work that they thought was worth mentioning, or because the way was organized in a way that they wouldn't have organized it. Anyone self-confident enough to believe that they could have done a better job of designing, conducting, or presenting the research can reject you for not doing what they would have done. -->

<!-- Destroy trust in the review process -->

When authors submit to a review process that uses subjective metrics, rather than scientific objectivity, they will optimize for those metrics. This reduced integrity, as some authors will try to inflate their importance of their findings or outright cheat. It also wastes a lot of time, as authors will take a paper that only builds on five or ten other prior papers worth citing, but will then add 50 or 100 citations so as not to have a below-average citation count and to ensure they don't risk citing work by potential reviewers who might fault the paper for not being deferential to their past contributions. Writing papers defensively in anticipation of subjective reviewing can be exhausting, especially when one failure to appease a reviewer's ego can set your publication date back by months or years.

But the real cost is to mental health.





<!-- As a member of a peer review committee, can dismiss a paper by arguing that authors should do a better job justifying the importance of the question they are investigating, or because the authors weren't sufficiently deferential to prior research, or because they didn't structure to put sections an order that reviewers prefer. -->

### Curation


#### Biasing participation to exclude

As a new graduate student, learning to recognize the abusiveness of this practice is key to surviving it and, hopefully, refusing to join those who accept as necessary (or at least inevitable).

You don't have the least power, and the system is designed to protect those with power over you.
Those who have power 
Your paper may be rejected because reviewers who compete with your advisor don't like the topic your advisors suggested you work on, or because you failed to cite their work, or because they didn't like.  . 

# Why is peer review abusive

Evaluate science to ensure that results don't mislead. (Both )

Determine whether research is novel, interesting, or otherwise significant enough to warrant publication at the venue it is being evaluated for.

<!-- Ranking the subjective value of creative work, and those who create it, is incompatible with the scientific process. -->

# It's not okay

Everyone thinks that the review process is random and that feedback is often unconstructive, and often abusive.  Everyone seems to have stories of reviewers who didn't read papers, who intentionally kept competing work out, or who rejected work because the reviewers' favorite work (often their own) wasn't cited.
Reviewer 2 memes.

Yet, nobody thinks they or their are that reviewer, even though many of us frequently confess to delaying reviews until the last minute when we have no choice but to rush them.  The number of peers we think of as abusive or careless and the number of abusive and careless reviews are inconsistent.

Our continued faith in the ritual of peer ritual, despite all the evidence we see as we and our students suffer its abuses, can feel cultish to the new initiate to our tribe.  The best time to prepare for this reality is now, before you establish your loyalty to the tribe, so that you can recognize how abusive it is and resolve not to carry that abuse forward.

# Biases participation in science

You have to be "thick skinned" enough to survive as a scientist despite this abusive process.
You have to be okay with participating in, and thus being complicit in the process.
Values protecting the anonymity of people with more power than you (reviewers) over your mental health.  (Anonymity is designed to protect junior faculty, but students can only aspire to have the power of those who get to subjectively evaluate the importance of their work anonymously and without consequences for errors.)


# 

# Compromises scientific integrity

# Delays the release of information


# Alternatives

Split these two purposes.

Even better, evaluate experiments before they are conducted!


<!--

What you can do:

Learning to recognize toxic behavior and rituals helps you to prevent yourself from being blinded by it, and becoming complicit in it.  Acknowledging the problem is a huge step!


-->
